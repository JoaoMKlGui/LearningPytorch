{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPx7hTqvw6M0VRLlui3SdRV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoMKlGui/LearningPytorch/blob/main/IdentifyingNumbers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qspznTyFZEh4",
        "outputId": "c3a1df31-b355-4375-8307-82f3d496d6db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 407748923.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 33658153.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 101540029.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7826840.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "epoch 0 :  0.07968434691429138\n",
            "epoch 1 :  0.055770471692085266\n",
            "epoch 2 :  0.027678372338414192\n",
            "epoch 3 :  0.017150210216641426\n",
            "epoch 4 :  0.012407481670379639\n",
            "epoch 5 :  0.009691692888736725\n",
            "epoch 6 :  0.007801945321261883\n",
            "epoch 7 :  0.006557391956448555\n",
            "epoch 8 :  0.005838211625814438\n",
            "epoch 9 :  0.005194349214434624\n",
            "epoch 10 :  0.004582924768328667\n",
            "epoch 11 :  0.003987473901361227\n",
            "epoch 12 :  0.0035695875994861126\n",
            "epoch 13 :  0.003277648240327835\n",
            "epoch 14 :  0.003266396000981331\n",
            "epoch 15 :  0.0034250349272042513\n",
            "epoch 16 :  0.0037925466895103455\n",
            "epoch 17 :  0.004389398265630007\n",
            "epoch 18 :  0.0020485343411564827\n",
            "epoch 19 :  0.000824176415335387\n",
            "epoch 20 :  8.197729039238766e-05\n",
            "epoch 21 :  8.328775584232062e-05\n",
            "epoch 22 :  7.860360346967354e-05\n",
            "epoch 23 :  6.613073492189869e-05\n",
            "epoch 24 :  4.8250079998979345e-05\n",
            "epoch 25 :  4.299608917790465e-05\n",
            "epoch 26 :  8.020235327421688e-06\n",
            "epoch 27 :  4.4017830077791587e-05\n",
            "epoch 28 :  5.2033668907824904e-05\n",
            "epoch 29 :  0.00017124912119470537\n",
            "epoch 30 :  3.914830449502915e-05\n",
            "epoch 31 :  4.167780571151525e-05\n",
            "epoch 32 :  3.161214044666849e-05\n",
            "epoch 33 :  0.00010194671631325036\n",
            "epoch 34 :  4.332584285293706e-05\n",
            "epoch 35 :  7.439192813762929e-06\n",
            "epoch 36 :  1.5869579783611698e-06\n",
            "epoch 37 :  2.395666524535045e-05\n",
            "epoch 38 :  5.677038188878214e-06\n",
            "epoch 39 :  5.097877874504775e-05\n",
            "epoch 40 :  7.368204478552798e-06\n",
            "epoch 41 :  5.774180067419366e-07\n",
            "epoch 42 :  8.195589771275991e-07\n",
            "epoch 43 :  2.1606656730455143e-07\n",
            "epoch 44 :  9.685750512744562e-08\n",
            "epoch 45 :  7.450577754752885e-08\n",
            "epoch 46 :  5.215404996761208e-08\n",
            "epoch 47 :  4.09781861776537e-08\n",
            "epoch 48 :  3.352760913344355e-08\n",
            "epoch 49 :  2.9802318834981634e-08\n",
            "epoch 50 :  1.862644971595273e-08\n",
            "epoch 51 :  1.862644971595273e-08\n",
            "epoch 52 :  1.862644971595273e-08\n",
            "epoch 53 :  1.4901160305669237e-08\n",
            "epoch 54 :  1.1175870007207322e-08\n",
            "epoch 55 :  1.1175870007207322e-08\n",
            "epoch 56 :  1.1175870007207322e-08\n",
            "epoch 57 :  1.1175870007207322e-08\n",
            "epoch 58 :  1.1175870007207322e-08\n",
            "epoch 59 :  7.450580152834618e-09\n",
            "epoch 60 :  7.450580152834618e-09\n",
            "epoch 61 :  7.450580152834618e-09\n",
            "epoch 62 :  7.450580152834618e-09\n",
            "epoch 63 :  7.450580152834618e-09\n",
            "epoch 64 :  3.725290076417309e-09\n",
            "epoch 65 :  3.725290076417309e-09\n",
            "epoch 66 :  0.0\n",
            "epoch 67 :  0.0\n",
            "epoch 68 :  0.0\n",
            "epoch 69 :  0.0\n",
            "epoch 70 :  0.0\n",
            "epoch 71 :  0.0\n",
            "epoch 72 :  0.0\n",
            "epoch 73 :  0.0\n",
            "epoch 74 :  0.0\n",
            "epoch 75 :  0.0\n",
            "epoch 76 :  0.0\n",
            "epoch 77 :  0.0\n",
            "epoch 78 :  0.0\n",
            "epoch 79 :  0.0\n",
            "epoch 80 :  0.0\n",
            "epoch 81 :  0.0\n",
            "epoch 82 :  0.0\n",
            "epoch 83 :  0.0\n",
            "epoch 84 :  0.0\n",
            "epoch 85 :  0.0\n",
            "epoch 86 :  0.0\n",
            "epoch 87 :  0.0\n",
            "epoch 88 :  0.0\n",
            "epoch 89 :  0.0\n",
            "epoch 90 :  0.0\n",
            "epoch 91 :  0.0\n",
            "epoch 92 :  0.0\n",
            "epoch 93 :  0.0\n",
            "epoch 94 :  0.0\n",
            "epoch 95 :  0.0\n",
            "epoch 96 :  0.0\n",
            "epoch 97 :  0.0\n",
            "epoch 98 :  0.0\n",
            "epoch 99 :  0.0\n"
          ]
        }
      ],
      "source": [
        "from torch import save, load \n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor \n",
        "\n",
        "train = datasets.MNIST(root=\"data\", download=True, train=True, transform=ToTensor()) \n",
        "\n",
        "#root fala de onde vamos tirar os dados aparentemente\n",
        "#o download é pra indicar se vamos ter que fazer o download ou se já está na máquina o dataset\n",
        "#o arg train é pra separar o dataset em um dataset feito para treino \n",
        "#como é imagem, utilizamos o transform para falar como queremos manipular/transformar o input. Nesse caso, mudando para um tensor\n",
        "\n",
        "dataset = DataLoader(train, batch_size=32)\n",
        "\n",
        "#utilizando a estratégia de dividir em batches de 32 samples cada e passando train(nossa variavel que guarda as imagens) para o DataLoader fazer as divisões\n",
        "\n",
        "\n",
        "class ImageClassifier(nn.Module):  #declarando a classe ImageClassifier como sendo uma subclasse de nn.Module\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Conv2d(1, 32, (3,3)), #como vamos classificar e trabalhar com imagens, utilizar redes convolocionais parece ser a melhor opcao. O tamanho do input é 1 pois a imagem é em preto e branco, logo, só possui 1 camada (seria 3 se fosse rgb eu acho)\n",
        "        nn.ReLU(), #primeira funcao de ativacao é a relu\n",
        "        nn.Conv2d(32, 64, (3,3)), \n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, 128, (3,3)), #a partir daqui eu adicionei as camadas para ir aprendendo algumas coisas. nada foi pego do vídeo\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128,128, (3,3)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128,128, (3,3)),\n",
        "        nn.Flatten(), #transformando a imagem em um tensor de dimensão única\n",
        "        nn.Linear(128 * (28-10) * (28-10), 10) #última camada. São 256 entradas e 256 saídas. A cada camada da RN, a gente tá tirando 2 pixels (não sei o motivo já que o cara do vídeo não falou). Então devemos subtrair do shape das imagens 2*4 = 8\n",
        "                 #o output deve ser o número de classes (no nosso caso, vai de 0 a 9). logo, 10 é o tamanho\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "\n",
        "#criar as instancias da rede neural\n",
        "\n",
        "clf = ImageClassifier().to('cuda')     #pra acelerar o processo vamos mandar pra GPU as coisas (não entendi muito bem essa parte de cuda, mas sei que é pra acelerar o processo porque é mais rápido)\n",
        "optimizer = SGD(clf.parameters(), lr = 0.01)\n",
        "lossFunction = nn.CrossEntropyLoss()\n",
        "\n",
        "# criando a parte de treinamento\n",
        "\n",
        "for epoch in range(100): #treinando para 10 epochs\n",
        "  for batch in dataset: #vamos treinar uma vez de cada para cada divisão de dados\n",
        "    X, Y = batch # cada elemento (batch) do dataset (divisão feita pelo dataloader) vem com 2 elementos, o X e o Y\n",
        "    X, Y = X.to('cuda'), Y.to('cuda') #mandando nossos dados para a gpu\n",
        "    \n",
        "    yPredict = clf(X) #criando as previsões\n",
        "\n",
        "    loss = lossFunction(yPredict, Y) #passando a previsão e o Y esperado para calcular a perda\n",
        "    \n",
        "    #aplicando backprop\n",
        "    optimizer.zero_grad() #se tiver algum gradiente na memoria (eu acho que eles ficam na memoria, n sei), preciso zerar eles\n",
        "    loss.backward() #calculando o gradiente do backprop\n",
        "    optimizer.step()\n",
        "\n",
        "  print(\"epoch\", epoch, \": \", loss.item())\n",
        "\n",
        "with open('modelo.pt', 'wb') as f:\n",
        "  save(clf.state_dict(), f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image \n",
        "import torch\n",
        "\n",
        "with open('modelo.pt', 'rb') as f:\n",
        "  clf.load_state_dict(load(f))\n",
        "\n",
        "img = Image.open('img_1.jpg')\n",
        "img.convert('1')\n",
        "imgTensor = ToTensor()(img).unsqueeze(0).to('cuda')\n",
        "print(torch.argmax(clf(imgTensor)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4c2jpRDN88f",
        "outputId": "639c782f-2b07-4cff-92d2-756fdfed96db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img2 = Image.open('img_2.jpg')\n",
        "img2.convert('1')\n",
        "img2Tensor = ToTensor()(img2).unsqueeze(0).to('cuda')\n",
        "print(torch.argmax(clf(imtg2Tensor)))"
      ],
      "metadata": {
        "id": "zqSHkr-gib2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef81297b-4b68-4e62-a87c-ebb896ea521b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yOK-Grvb2FTs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}