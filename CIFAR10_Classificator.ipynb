{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoMKlGui/LearningPytorch/blob/main/CIFAR10_Classificator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyw2iEw5d537"
      },
      "source": [
        "# CIFAR-10 Database classificator\n",
        "A NN that classifies the images from CIFAR-10 database applying CNN's fro Pytorch\n",
        "\n",
        "The classes that it identifies are:\n",
        "- Airplane\n",
        "- Automobile\n",
        "- Bird\n",
        "- Cat\n",
        "- Deer\n",
        "- Dog\n",
        "- Frog\n",
        "- Horse\n",
        "- Ship\n",
        "- Truck\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbUipOhy8at0",
        "outputId": "dcf685e6-10a7-44e0-c43d-ff2a4cfba5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n"
          ]
        }
      ],
      "source": [
        "# Libraries\n",
        "!pip install torchmetrics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchmetrics import Accuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zrPPpw9Z-H4x"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAJAZAm_9rUA",
        "outputId": "8a5906b0-808c-4c01-afad-61c92e27b1e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# GPU / CPU\n",
        "if torch.cuda.is_available():\n",
        "   device = \"cuda:0\"\n",
        "   print(torch.cuda.get_device_name(device))\n",
        "else:\n",
        "   device = \"cpu\"\n",
        "print(device)\n",
        "device = torch.device(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNfPqpWk9zl6",
        "outputId": "0552bdfc-d0fd-483b-e57d-a1a29ae18672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12900614.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "raw_train = datasets.CIFAR10(root='data', train=True, transform=ToTensor(),download=True)\n",
        "raw_train\n",
        "\n",
        "#10 categories, coloured 32x32 images, 50000 images for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXaWwiO8-cC2",
        "outputId": "0c330b0e-5466-4137-9fb1-eba40bd1f991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "raw_test = datasets.CIFAR10(root='data', train=False, transform=ToTensor(), download=True)\n",
        "raw_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szo7bFXvl-wR"
      },
      "source": [
        "Classes that will be predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa9UQAHNsEyY",
        "outputId": "2d70421b-0597-4b9a-cf62-c5866e1a283b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "raw_test.classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taZ28ERamCy-"
      },
      "source": [
        "Dividing my train data into a train dataset and a validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3pmJHml4m7ne"
      },
      "outputs": [],
      "source": [
        "train, validation = train_test_split(raw_train, test_size=0.2, stratify = raw_train.targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcYf8gvVmMfP"
      },
      "source": [
        "Converting to DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eEeIJC5BazG",
        "outputId": "4d3d5c6c-2578-411c-c2fb-d00d44b2db70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fa56cd83160>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "test_loader = DataLoader(dataset = raw_test)\n",
        "train_loader = DataLoader(dataset=train, batch_size = 10, shuffle = True)\n",
        "validation_loader = DataLoader(dataset=validation)\n",
        "\n",
        "train_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lORdsRXVCJZg"
      },
      "outputs": [],
      "source": [
        "#Neural Network\n",
        "\n",
        "class Classificator(nn.Module):\n",
        "\n",
        "  #32x32 images\n",
        "  #lost 2 pixel p/conv layer\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 32, (3,3)),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(32, 64, (3,3)),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Conv2d(64, 128, (3,3)),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=(2,2))\n",
        "    )\n",
        "\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Conv2d(128, 256, (3,3)),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=(2,2))\n",
        "    )\n",
        "\n",
        "    self.dense_linear = nn.Sequential(\n",
        "        nn.Linear(256*(5)*(5), 256),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.dropout1 = nn.Dropout(p=0.25)\n",
        "\n",
        "    self.dropout2 = nn.Dropout(p=0.50)\n",
        "\n",
        "    self.out_linear = nn.Sequential(\n",
        "        nn.Linear(256, 10),\n",
        "        nn.ReLU(),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "    x = self.dropout1(x)\n",
        "    x = self.dense_linear(x.flatten(1))\n",
        "    x = self.dropout2(x)\n",
        "    x = self.out_linear(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6YpMBt-l3KW"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn-K_RWHXs8N",
        "outputId": "2384de00-300e-4c69-fe9a-4582362d35d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época: 1, Accuracy: 47.88\n",
            "Época: 2, Accuracy: 54.90\n",
            "Época: 3, Accuracy: 57.13\n",
            "Época: 4, Accuracy: 58.94\n",
            "Época: 5, Accuracy: 61.27\n",
            "Época: 6, Accuracy: 61.61\n",
            "Época: 7, Accuracy: 62.93\n",
            "Época: 8, Accuracy: 63.94\n",
            "Época: 9, Accuracy: 63.89\n",
            "Época: 10, Accuracy: 65.02\n",
            "Época: 11, Accuracy: 65.48\n",
            "Época: 12, Accuracy: 69.35\n",
            "Época: 13, Accuracy: 71.41\n",
            "Época: 14, Accuracy: 70.07\n",
            "Época: 15, Accuracy: 71.49\n",
            "Época: 16, Accuracy: 72.42\n",
            "Época: 17, Accuracy: 73.49\n",
            "Época: 18, Accuracy: 73.84\n",
            "Época: 19, Accuracy: 74.01\n",
            "Época: 20, Accuracy: 73.57\n",
            "Época: 21, Accuracy: 74.17\n",
            "Época: 22, Accuracy: 75.50\n",
            "Época: 23, Accuracy: 74.82\n",
            "Época: 24, Accuracy: 75.06\n",
            "Época: 25, Accuracy: 75.06\n",
            "Época: 26, Accuracy: 75.26\n",
            "Época: 27, Accuracy: 74.65\n",
            "Época: 28, Accuracy: 76.15\n",
            "Época: 29, Accuracy: 76.06\n",
            "Época: 30, Accuracy: 76.33\n",
            "Época: 31, Accuracy: 76.60\n",
            "Época: 32, Accuracy: 76.07\n",
            "Época: 33, Accuracy: 75.97\n",
            "Época: 34, Accuracy: 76.66\n",
            "Época: 35, Accuracy: 77.33\n",
            "Época: 36, Accuracy: 76.45\n",
            "Época: 37, Accuracy: 76.74\n",
            "Época: 38, Accuracy: 76.60\n",
            "Época: 39, Accuracy: 77.53\n",
            "Época: 40, Accuracy: 77.54\n",
            "Época: 41, Accuracy: 77.55\n",
            "Época: 42, Accuracy: 77.67\n",
            "Época: 43, Accuracy: 77.33\n",
            "Época: 44, Accuracy: 77.68\n",
            "Época: 45, Accuracy: 77.86\n",
            "Época: 46, Accuracy: 77.80\n",
            "Época: 47, Accuracy: 77.87\n",
            "Época: 48, Accuracy: 78.43\n",
            "Época: 49, Accuracy: 78.10\n",
            "Época: 50, Accuracy: 78.06\n",
            "Época: 51, Accuracy: 77.96\n",
            "Época: 52, Accuracy: 78.42\n",
            "Época: 53, Accuracy: 78.20\n",
            "Época: 54, Accuracy: 78.48\n",
            "Época: 55, Accuracy: 78.33\n",
            "Época: 56, Accuracy: 77.68\n",
            "Época: 57, Accuracy: 78.35\n",
            "Época: 58, Accuracy: 78.09\n",
            "Época: 59, Accuracy: 77.79\n",
            "Época: 60, Accuracy: 78.16\n",
            "Época: 61, Accuracy: 79.13\n",
            "Época: 62, Accuracy: 78.10\n",
            "Época: 63, Accuracy: 79.03\n",
            "Época: 64, Accuracy: 78.67\n",
            "Época: 65, Accuracy: 78.76\n",
            "Época: 66, Accuracy: 78.81\n",
            "Época: 67, Accuracy: 78.57\n",
            "Época: 68, Accuracy: 78.84\n",
            "Época: 69, Accuracy: 78.67\n",
            "Época: 70, Accuracy: 78.84\n",
            "Época: 71, Accuracy: 78.99\n",
            "Época: 72, Accuracy: 79.07\n",
            "Época: 73, Accuracy: 78.99\n",
            "Época: 74, Accuracy: 78.55\n",
            "Época: 75, Accuracy: 79.33\n",
            "Época: 76, Accuracy: 79.07\n",
            "Época: 77, Accuracy: 79.32\n",
            "Época: 78, Accuracy: 79.11\n",
            "Época: 79, Accuracy: 79.09\n",
            "Época: 80, Accuracy: 79.62\n",
            "Época: 81, Accuracy: 79.42\n",
            "Época: 82, Accuracy: 79.70\n",
            "Época: 83, Accuracy: 78.99\n",
            "Época: 84, Accuracy: 79.03\n",
            "Época: 85, Accuracy: 79.77\n",
            "Época: 86, Accuracy: 79.77\n",
            "Época: 87, Accuracy: 79.76\n",
            "Época: 88, Accuracy: 79.44\n",
            "Época: 89, Accuracy: 79.61\n",
            "Época: 90, Accuracy: 79.79\n",
            "Época: 91, Accuracy: 78.99\n",
            "Época: 92, Accuracy: 79.60\n",
            "Época: 93, Accuracy: 79.52\n",
            "Época: 94, Accuracy: 79.72\n",
            "Época: 95, Accuracy: 79.53\n",
            "Época: 96, Accuracy: 80.04\n",
            "Época: 97, Accuracy: 79.58\n",
            "Época: 98, Accuracy: 79.58\n",
            "Época: 99, Accuracy: 79.06\n",
            "Época: 100, Accuracy: 80.06\n"
          ]
        }
      ],
      "source": [
        "model = Classificator().to('cuda')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "accuracy = Accuracy(task='multiclass', num_classes= 10).to('cuda')\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "    acuraciaAcumulador = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    model.train()\n",
        "    # training\n",
        "\n",
        "    for train_x, train_y in train_loader:\n",
        "\n",
        "      # predict\n",
        "\n",
        "      train_x, train_y = train_x.to('cuda'), train_y.to('cuda')\n",
        "\n",
        "      outputs = model(train_x)\n",
        "      outputs = outputs.squeeze()\n",
        "\n",
        "      # calculating loss\n",
        "      batch_loss = loss_function(outputs, train_y)\n",
        "\n",
        "      # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
        "      optimizer.zero_grad()\n",
        "      batch_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      for valid_x, valid_y in validation_loader:\n",
        "\n",
        "        valid_x, valid_y = valid_x.to('cuda'), valid_y.to('cuda')\n",
        "\n",
        "        outputs = model(valid_x)\n",
        "        outputs.squeeze()\n",
        "\n",
        "        y_true.append(valid_y)\n",
        "        y_pred.append(torch.argmax(outputs, dim=1))\n",
        "\n",
        "        acuraciaAcumulador += accuracy(outputs, valid_y)\n",
        "\n",
        "      acuraciaTotal = acuraciaAcumulador / len(validation_loader)\n",
        "      print(f'Época: {i+1:d}, Accuracy: {100*acuraciaTotal:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A0n7ToVzqEaZ"
      },
      "outputs": [],
      "source": [
        "from torch import save, load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsu3LIm6lzD9"
      },
      "source": [
        "Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "REpzB-AN9xs6"
      },
      "outputs": [],
      "source": [
        "with open('modelo.pt', 'wb') as f:\n",
        "  save(model.state_dict(), f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwWNHutvloXv"
      },
      "source": [
        "Testing and evalutating the model with accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PBVhQEViqQFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dde6a0d2-1cc5-4632-ce00-a1d84c832bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 80.0\n"
          ]
        }
      ],
      "source": [
        "with open('modelo.pt', 'rb') as f:\n",
        "  model.load_state_dict(load(f))\n",
        "  acumulador = 0\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "\n",
        "    for test_x, test_y in test_loader:\n",
        "\n",
        "      test_x, test_y = test_x.to('cuda'), test_y.to('cuda')\n",
        "\n",
        "      outputs = model(test_x)\n",
        "      outputs.squeeze()\n",
        "\n",
        "      acumulador += accuracy(outputs, test_y).item()\n",
        "\n",
        "    acuracia_teste = acumulador / len(test_loader)\n",
        "    print('Test Accuracy:', acuracia_teste*100)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a4JyWLicX_6w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/V/83mp0FN/7DNjzB9qUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}